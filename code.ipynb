{
 "cells": [
  {
   "cell_type": "code",
   "id": "7b94592f73f21d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T01:35:37.522383Z",
     "start_time": "2025-05-20T01:35:37.506531Z"
    }
   },
   "source": [
    "# import kaggle\n",
    "# import zipfile\n",
    "#\n",
    "# kaggle datasets download -d bittlingmayer/amazonreviews\n",
    "# with zipfile.ZipFile(\"amazonreviews.zip\", \"r\") as zip_ref:\n",
    "#      zip_ref.extractall(\"amazonreviews\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6c8db679143eb27d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:23:14.560161Z",
     "start_time": "2025-05-24T06:23:10.279948Z"
    }
   },
   "source": [
    "import sklearn                      # Machine Learning\n",
    "import torch                        # PyTorch\n",
    "import tensorflow                   # ditto\n",
    "\n",
    "import pandas as pd                 # Data manipulation\n",
    "import numpy as np                  # Number operations\n",
    "import math                         # ditto\n",
    "\n",
    "import matplotlib.pyplot as plt     # Plotting\n",
    "import matplotlib.image as mpimg    # Image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import seaborn as sns\n",
    "\n",
    "import bz2\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:27:09.702394Z",
     "start_time": "2025-05-21T14:27:09.686748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_data = {\n",
    "    \"fastText\": 0,\n",
    "    \"BERT\": 0,\n",
    "    \"gpt-4o-mini\": 0,\n",
    "    \"LSTM\": 0,\n",
    "    \"textCNN\": 0,\n",
    "    \"TF-IDF + NaiveBayes\": 0,\n",
    "    \"TF-IDF + LogisticRegression\": 0\n",
    "}"
   ],
   "id": "46ed8deccde21485",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_data",
   "id": "becee158549ffaee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:10:19.107260Z",
     "start_time": "2025-05-23T15:10:19.075591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save data\n",
    "import pickle\n",
    "with open('session.pkl', 'wb') as f:\n",
    "    pickle.dump(plot_data, f)"
   ],
   "id": "57c4852f5eaac44",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:19:03.633516Z",
     "start_time": "2025-05-24T04:19:02.785722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "import pickle\n",
    "with open('session.pkl', 'rb') as f:\n",
    "    plot_data = pickle.load(f)"
   ],
   "id": "2843f861ecf71017",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "96f99d46cdeee051",
   "metadata": {},
   "source": [
    "Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "id": "95b6a394433d2ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T05:55:44.480887Z",
     "start_time": "2025-05-24T05:55:30.309627Z"
    }
   },
   "source": [
    "trainsize = 180000\n",
    "testsize = 20000\n",
    "\n",
    "bert_trainsize = 1800\n",
    "bert_testsize = 200\n",
    "\n",
    "def sepcontent(line):\n",
    "    rating, content = line.split(\" \", 1)\n",
    "    rating = rating.replace(\"__label__\", \"\")\n",
    "    title, comment = content.split(\": \", 1)\n",
    "    return int(rating), title, comment\n",
    "\n",
    "def bz2todf(originfile, limit=1000):\n",
    "    ratings, content, raws, berts = [], [], [], []\n",
    "    with bz2.open(originfile, mode='rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= limit:\n",
    "                break\n",
    "            line = line.strip()\n",
    "\n",
    "            rating, title, comment = sepcontent(line)\n",
    "            bert_input = f\"{title} [SEP] {comment}\"\n",
    "            content_input = f\"{title}: {comment}\"\n",
    "\n",
    "            raws.append(line)\n",
    "            ratings.append(rating)\n",
    "            content.append(content_input)\n",
    "            berts.append(bert_input)\n",
    "\n",
    "    raw_df = pd.DataFrame(raws, columns=[\"raw\"])\n",
    "    bert_df = pd.DataFrame({\"rating\": ratings, \"bert\": berts})\n",
    "    normal_df = pd.DataFrame({\"rating\": ratings, \"text\": content})\n",
    "\n",
    "    return raw_df, bert_df, normal_df\n",
    "\n",
    "ft_traindf, bert_traindf, normal_traindf = bz2todf(\"amazonreviews/train.ft.txt.bz2\", trainsize)\n",
    "ft_testdf, bert_testdf, normal_testdf = bz2todf(\"amazonreviews/test.ft.txt.bz2\", testsize)\n",
    "\n",
    "bert_traindf = bert_traindf.iloc[:bert_trainsize]\n",
    "bert_testdf = bert_traindf.iloc[:bert_testsize]"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "d212716869d81547",
   "metadata": {},
   "source": "1. fastText"
  },
  {
   "cell_type": "code",
   "id": "eae04aa8a0ddd482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:35:43.045909Z",
     "start_time": "2025-05-22T08:35:42.648866Z"
    }
   },
   "source": "import fasttext",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e3784438fc75ee80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:36:06.455910Z",
     "start_time": "2025-05-22T08:35:44.417776Z"
    }
   },
   "source": [
    "ft_traindf.to_csv(\"train.txt\", index=False, sep=\" \", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "\n",
    "train_start = time.time()\n",
    "ft_model = fasttext.train_supervised(\"train.txt\", label_prefix=\"__label__\", thread=4, epoch=10)\n",
    "train_time = time.time() - train_start"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "b170ae488c21e232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:36:14.972836Z",
     "start_time": "2025-05-22T08:36:14.847864Z"
    }
   },
   "source": [
    "clean = [x for x in ft_testdf[\"raw\"]]\n",
    "clean = [x.replace(\"__label__1\", \"\").replace(\"__label__2\", \"\") for x in clean]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "9db4c2ffe28d07a0",
   "metadata": {},
   "source": [
    "test_start = time.time()\n",
    "predict = [int(ft_model.predict(x)[0][0].replace(\"__label__\", \"\")) for x in clean]\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "truevalue = [int(x.split(\" \")[0].replace(\"__label__\", \"\")) for x in ft_testdf[\"raw\"]]\n",
    "accuracy = accuracy_score(truevalue, predict)\n",
    "confusion = confusion_matrix(truevalue, predict)\n",
    "\n",
    "plot_data[\"fastText\"] = [accuracy, train_time, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time:\", train_time)\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2331476a3b40ef5",
   "metadata": {},
   "source": [
    "2. BERT"
   ]
  },
  {
   "cell_type": "code",
   "id": "248669b825c83318",
   "metadata": {},
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cfd8e2bc6dfbc101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:43:16.543532Z",
     "start_time": "2025-05-22T08:43:12.504891Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = bert_traindf.bert, bert_testdf.bert, bert_traindf.rating, bert_testdf.rating\n",
    "y_train = [x-1 for x in y_train]\n",
    "y_test = [x-1 for x in y_test]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encoding = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encoding = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "9aa8469477066180",
   "metadata": {},
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encoding[\"input_ids\"],\n",
    "    \"attention_mask\": train_encoding[\"attention_mask\"],\n",
    "    \"label\": list(y_train)\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encoding[\"input_ids\"],\n",
    "    \"attention_mask\": test_encoding[\"attention_mask\"],\n",
    "    \"label\": list(y_test)\n",
    "})\n",
    "\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2) # classify to 2 types (0/1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e05a4391a815057",
   "metadata": {},
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "train_start = time.time()\n",
    "trainer.train()\n",
    "train_time = time.time() - train_start"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "658ddd9432699d31",
   "metadata": {},
   "source": [
    "test_start = time.time()\n",
    "prediction = trainer.predict(test_dataset)\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "y_pred = prediction.predictions.argmax(axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plot_data[\"BERT\"] = [accuracy, train_time, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time:\", train_time)\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "644b7e869378ada6",
   "metadata": {},
   "source": [
    "3. OpenAI GPT"
   ]
  },
  {
   "cell_type": "code",
   "id": "914ce5e2fc0e4435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T13:10:49.880402Z",
     "start_time": "2025-05-23T13:10:46.679824Z"
    }
   },
   "source": "import openai",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T13:25:12.707179Z",
     "start_time": "2025-05-23T13:25:12.641608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "textbatch = 10\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=\"\"\n",
    ")\n",
    "aimodel = \"gpt-4o-mini\"\n",
    "\n",
    "def classify_with_gpt(i):\n",
    "    inputtexts = \"\"\n",
    "    start = i*textbatch\n",
    "    currentbatch = min(start+textbatch, len(bert_testdf)) - start\n",
    "    for x in range(start, start+currentbatch):\n",
    "        text = bert_testdf.bert[x]\n",
    "        inputtexts = inputtexts + f\"Text {x-start+1}: {text}\\n\\n\"\n",
    "\n",
    "    prompt = f\"\"\"You are a sentiment classifier that returns multiple either 1 or 2 with separated commas for each text. Return 1 when the text is negative review, and return 2 when the text is positive review. Here is an example:\n",
    "\n",
    "Text 1: Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n",
    "\n",
    "Text 2: Awful beyond belief!: I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n",
    "\n",
    "Text 3: Disappointed: I read the reviews,made my purchase and was very disappointed. The charger is convenient by charging all four batteries at once but the charge only lasts a very short time. I now have to go and find batteries that will give me longer life than the kodak NiMH AA batteries.\n",
    "\n",
    "Because the first text is a positive review, the second text is a negative review, and the third text is also a negative review, you would return \"2,1,1\"\n",
    "\n",
    "Now, here is {currentbatch} texts I want you to return the sentiment values of:\n",
    "\n",
    "{inputtexts}Since there are {currentbatch} texts, you have to return in the folowing format: {\"X\"+\",X\"*(currentbatch-1)}\n",
    "\n",
    "with each \"X\" is 1 or 2 depending on the sentiment of the review text\n",
    "\n",
    "Return: \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=aimodel,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=currentbatch*2 + 10,\n",
    "    )\n",
    "\n",
    "    return start, currentbatch, response.choices[0].message.content.strip()"
   ],
   "id": "3a5f99171478a5f3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = []\n",
    "test_start = time.time()\n",
    "for x in range(0, math.ceil(len(bert_testdf)/textbatch)):\n",
    "    start, currentbatch, raw = classify_with_gpt(x)\n",
    "    print(f\"Start: {start}. Currentbatch: {currentbatch}. Result: {raw}\")\n",
    "    result.extend([int(x) for x in raw.split(\",\")])\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "accuracy = accuracy_score(bert_testdf['rating'], result)\n",
    "confusion = confusion_matrix(bert_testdf['rating'], result)\n",
    "\n",
    "plot_data[\"gpt-4o-mini\"] = [accuracy, np.nan, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time: 0\")\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "id": "1df3d8f7827dc107",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cbb426e0c801cfb5",
   "metadata": {},
   "source": [
    "4. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "id": "3dd0322a19047f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:39:18.623202Z",
     "start_time": "2025-05-22T09:39:18.579760Z"
    }
   },
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SpatialDropout1D, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "c2d21389ed36ffd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:27:29.496193Z",
     "start_time": "2025-05-22T10:26:40.083267Z"
    }
   },
   "source": [
    "voc_size = 20000\n",
    "max_length = 128\n",
    "tokenizer = Tokenizer(num_words=voc_size)\n",
    "tokenizer.fit_on_texts(normal_traindf.text)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train = tokenizer.texts_to_sequences(normal_traindf.text)\n",
    "train = pad_sequences(train, maxlen=max_length)\n",
    "test = tokenizer.texts_to_sequences(normal_testdf.text)\n",
    "test = pad_sequences(test, maxlen=max_length)\n",
    "\n",
    "keras_trainrating = np.array(normal_traindf.rating - 1).astype(\"float32\")"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=voc_size, output_dim=64))\n",
    "lstm_model.add(LSTM(units=32, return_sequences=True))\n",
    "lstm_model.add(SpatialDropout1D(rate=0.2))\n",
    "lstm_model.add(LSTM(units=32))\n",
    "lstm_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "id": "20fe1873b6694890",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"amazon_model.h5\", save_best_only=True)\n",
    "\n",
    "train_start = time.time()\n",
    "lstm_model.fit(train, keras_trainrating, epochs=2, validation_split=.1, callbacks=[checkpoint_cb])\n",
    "train_time = time.time() - train_start"
   ],
   "id": "b09d034b7353e011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_start = time.time()\n",
    "y_prob = lstm_model.predict(test)\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "y_pred = ((y_prob > 0.5).astype(int) + 1).flatten()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, normal_testdf.rating)\n",
    "confusion = confusion_matrix(y_pred, normal_testdf.rating)\n",
    "\n",
    "plot_data[\"LSTM\"] = [accuracy, train_time, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time:\", train_time)\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "id": "b15e59a51f5e6e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d98e2190026456b3",
   "metadata": {},
   "source": "5. textCNN"
  },
  {
   "cell_type": "code",
   "id": "176c2915a655b233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:08:35.696313Z",
     "start_time": "2025-05-22T11:08:35.648342Z"
    }
   },
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Concatenate, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:09:10.236259Z",
     "start_time": "2025-05-22T11:09:10.022835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "voc_size = 20000\n",
    "max_length = 128\n",
    "input_layer = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=voc_size, output_dim=128)(input_layer)\n",
    "\n",
    "conv_3 = Conv1D(128, 3, activation=\"relu\")(embedding)\n",
    "conv_4 = Conv1D(128, 4, activation=\"relu\")(embedding)\n",
    "conv_5 = Conv1D(128, 5, activation=\"relu\")(embedding)\n",
    "\n",
    "pool_3 = GlobalMaxPooling1D()(conv_3)\n",
    "pool_4 = GlobalMaxPooling1D()(conv_4)\n",
    "pool_5 = GlobalMaxPooling1D()(conv_5)\n",
    "\n",
    "concat = Concatenate()([pool_3, pool_4, pool_5])\n",
    "\n",
    "dropout = Dropout(0.5)(concat)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout) # >2 class = softmax\n",
    "\n",
    "cnn_model = Model(inputs=input_layer, outputs=output)\n",
    "cnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "keras_trainrating = np.array(normal_traindf.rating - 1).astype(\"float32\")"
   ],
   "id": "7fb8fd3dcc53585e",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"amazon_model.h5\", save_best_only=True)\n",
    "\n",
    "train_start = time.time()\n",
    "cnn_model.fit(train, keras_trainrating, epochs=2, validation_split=.1, callbacks=[checkpoint_cb])\n",
    "train_time = time.time() - train_start"
   ],
   "id": "29e44f38e7efdbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_start = time.time()\n",
    "y_prob = cnn_model.predict(test)\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "y_pred = ((y_prob > 0.5).astype(int) + 1).flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_pred, normal_testdf.rating)\n",
    "confusion = confusion_matrix(y_pred, normal_testdf.rating)\n",
    "\n",
    "plot_data[\"textCNN\"] = [accuracy, train_time, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time:\", train_time)\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "id": "51f681e2c2083c75",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5b3a84f8d276f5ac",
   "metadata": {},
   "source": "6. TF-IDF + Naive Bayes"
  },
  {
   "cell_type": "code",
   "id": "4650aad71dc0b348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:27:29.803886Z",
     "start_time": "2025-05-22T11:27:28.875503Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nb_model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "train_start = time.time()\n",
    "nb_fit = nb_model.fit(normal_traindf.text, normal_traindf.rating)\n",
    "train_time = time.time() - train_start\n",
    "\n",
    "test_start = time.time()\n",
    "predict = nb_fit.predict(normal_testdf.text)\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "accuracy = accuracy_score(predict, normal_testdf.rating)\n",
    "confusion = confusion_matrix(predict, normal_testdf.rating)\n",
    "\n",
    "plot_data[\"TF-IDF + NaiveBayes\"] = [accuracy, train_time, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time:\", train_time)\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "id": "f3924745b2159a40",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6cf8f3183b02dae",
   "metadata": {},
   "source": "7. TF-IDF + Logistic Regression"
  },
  {
   "cell_type": "code",
   "id": "dabe3d1cee098dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:28:45.257219Z",
     "start_time": "2025-05-22T11:28:43.633382Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr_model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "train_start = time.time()\n",
    "lr_fit = lr_model.fit(normal_traindf.text, normal_traindf.rating)\n",
    "train_time = time.time() - train_start\n",
    "\n",
    "test_start = time.time()\n",
    "predict = lr_fit.predict(normal_testdf.text)\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "accuracy = accuracy_score(predict, normal_testdf.rating)\n",
    "confusion = confusion_matrix(predict, normal_testdf.rating)\n",
    "\n",
    "plot_data[\"TF-IDF + LogisticRegression\"] = [accuracy, train_time, test_time, confusion]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Train Time:\", train_time)\n",
    "print(\"Test Time:\", test_time)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ],
   "id": "9057ee12d0f1c610",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data Viz",
   "id": "7c7f8deb92e772f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "backgroundcolor = \"#F2E9E4\"\n",
    "\n",
    "plot_data"
   ],
   "id": "db7252d462e29765",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot: Accuracy",
   "id": "931bced4a59c9e91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T05:48:55.669228Z",
     "start_time": "2025-05-24T05:48:55.627954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imgsize = 16\n",
    "def getImageDict():\n",
    "    imagedict = {}\n",
    "    imagedir = lambda x: f\"Images/Script_4/{x}.png\"\n",
    "    for model in plot_data.keys():\n",
    "        image = mpimg.imread(imagedir(model))\n",
    "        imagebox = OffsetImage(image, zoom= imgsize/(image.shape[0]))\n",
    "\n",
    "        imagedict[model] = imagebox\n",
    "    return imagedict"
   ],
   "id": "1af801d1f0a52478",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_list = plot_data.keys()\n",
    "\n",
    "colordict = {\n",
    "    \"fastText\": \"#c3506e\",\n",
    "    \"BERT\": \"#d4af37\",\n",
    "    \"gpt-4o-mini\": \"#20856a\",\n",
    "    \"LSTM\": \"#3b6ca3\",\n",
    "    \"textCNN\": \"#e3822d\",\n",
    "    \"TF-IDF + NaiveBayes\": \"#4c9141\",\n",
    "    \"TF-IDF + LogisticRegression\": \"#7e5ca3\"\n",
    "}\n",
    "curImageDict = getImageDict()\n",
    "\n",
    "raw_values = [x[0] for x in plot_data.values()]\n",
    "label_values = [(lambda x: f\"{x:.1%}\")(x) for x in raw_values]\n",
    "\n",
    "zipped = list(zip(raw_values, label_values, model_list))\n",
    "zipped.sort(reverse=True)\n",
    "raw_values, label_values, model_list = zip(*zipped)\n",
    "\n",
    "plt.figure(figsize=(12, 8), facecolor=backgroundcolor)\n",
    "bars = plt.bar(model_list, raw_values, width=0.4)\n",
    "for v, (val, label, model) in enumerate(zip(raw_values, label_values, model_list)):\n",
    "    plt.text(v, val + 0.005, label, ha='center', va='bottom', fontsize=12, color=\"black\")\n",
    "for bar, model in zip(bars, model_list):\n",
    "    x, y = bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02\n",
    "    ab = AnnotationBbox(curImageDict[model], (x, y), xycoords='data', box_alignment=(0.5,0.5), frameon=False)\n",
    "    plt.gca().add_artist(ab)\n",
    "    bar.set_color(colordict[model])\n",
    "plt.title(\"Sentiment Analysis Models - Accuracy\", weight=\"bold\", y=1.05)\n",
    "plt.suptitle(\"Train Size: 180k (exc. BERT: 1.8k, gpt-4o-mini: -)\", y=0.91, x=0.52)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.8, 1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5faf6e521a750b9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_list = plot_data.keys()\n",
    "train_scalemult = bert_trainsize / trainsize\n",
    "test_scalemult = bert_testsize / testsize\n",
    "scaledmodel = [\"textCNN\", \"LSTM\", \"TF-IDF + LogisticRegression\", \"fastText\", \"TF-IDF + NaiveBayes\"]\n",
    "\n",
    "nanlambda = lambda x: not np.isnan(x) and x or 0\n",
    "labellambda = lambda x: x>1e2 and f\"{x:.0f}s\" or f\"{x:.3g}s\"\n",
    "\n",
    "trainlambda = lambda x, y: (x in scaledmodel) and y*train_scalemult or y\n",
    "testlambda = lambda x, y: (x in scaledmodel) and y*test_scalemult or y\n",
    "\n",
    "curImageDict = getImageDict()\n",
    "\n",
    "plt.figure(figsize=(12, 8), facecolor=backgroundcolor)\n",
    "def plotdata(raw_values, ylambda, sort, label, addimage):\n",
    "    y_values = [ylambda(x) for x in raw_values]\n",
    "    label_values = [labellambda(x) for x in raw_values]\n",
    "\n",
    "    plt.plot(model_list, y_values, marker=\"o\", label=label)\n",
    "    for v, (val, label, model) in enumerate(zip(y_values, label_values, model_list)):\n",
    "        plt.text(v, val + 0.1, label, ha='center', va='bottom', fontsize=12, color=\"black\")\n",
    "        if addimage:\n",
    "            ab = AnnotationBbox(curImageDict[model], (v, val + 0.7), xycoords='data', box_alignment=(0.5,0.5), frameon=False)\n",
    "            plt.gca().add_artist(ab)\n",
    "\n",
    "traintime_values = [trainlambda(x, y[1]) for x, y in plot_data.items()]\n",
    "testtime_values = [testlambda(x, y[2]) for x, y in plot_data.items()]\n",
    "totaltime_values = [nanlambda(traintime_values[x]) + testtime_values[x] for x in range(len(traintime_values))]\n",
    "\n",
    "zipped = list(zip(totaltime_values, traintime_values, testtime_values, model_list))\n",
    "zipped.sort(reverse=True)\n",
    "totaltime_values, traintime_values, testtime_values, model_list = zip(*zipped)\n",
    "\n",
    "plotdata(\n",
    "    totaltime_values,\n",
    "    lambda x: math.log10(x) + 2,\n",
    "    True,\n",
    "    \"Total Time\",\n",
    "    True\n",
    ")\n",
    "\n",
    "plotdata(\n",
    "    traintime_values,\n",
    "    lambda x: not np.isnan(x) and math.log10(x) or x,\n",
    "    False,\n",
    "    \"Training Time\",\n",
    "    False\n",
    ")\n",
    "\n",
    "plotdata(\n",
    "    testtime_values,\n",
    "    lambda x: math.log10(x),\n",
    "    False,\n",
    "    \"Testing Time\",\n",
    "    False\n",
    ")\n",
    "\n",
    "plt.title(\"Sentiment Analysis Models - Time Performance\", weight=\"bold\", y=1.05)\n",
    "plt.suptitle(\"Scaled to 1800 Training / 200 Test Samples\", y=0.91)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.legend()\n",
    "plt.ylim(-2.5, 6.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "362046f8a8d58d1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shortendict = {\n",
    "    \"TF-IDF + NaiveBayes\": \"NaiveBayes\",\n",
    "    \"TF-IDF + LogisticRegression\": \"LogRegress\"\n",
    "}\n",
    "shortenlambda = lambda x: shortendict[x] if x in shortendict.keys() else x\n",
    "grouplambda = lambda x, y: f\"{x:.1%}\\n({y})\"\n",
    "\n",
    "for model, value in plot_data.items():\n",
    "    matrix = value[3]\n",
    "    norm = matrix / matrix.sum(axis=1, keepdims=True)\n",
    "    group = [[grouplambda(norm[x,y], matrix[x,y]) for y in range(matrix.shape[1])] for x in range(matrix.shape[0])]\n",
    "    print(group)\n",
    "\n",
    "    plt.figure(figsize=(5, 4), facecolor=backgroundcolor)\n",
    "    sns.heatmap(norm, annot=group, fmt=\"\", cmap=\"viridis\",\n",
    "                xticklabels=[\"Pred 0\", \"Pred 1\"], yticklabels=[\"True 0\", \"True 1\"],\n",
    "                vmin=0, vmax=1)\n",
    "    plt.title(f\"{shortenlambda(model)} - Confusion Matrix\", weight=\"bold\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()"
   ],
   "id": "3a31eaee991a6993",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
